{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55a1f15f",
   "metadata": {},
   "source": [
    "# Start analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff755ec",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4881665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import sqlite3\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb79c5f",
   "metadata": {},
   "source": [
    "## Locate path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ec446e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: CSV found -> c:\\Users\\pc\\Desktop\\PROJECTS\\Supply_chain_analysis\\data\\Retail_supply_chain - Retails Order Full Dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Locate the CSV under a relative data folder: try ./data then ../data (if the notebook runs inside ./notebook).\n",
    "cwd = Path.cwd()\n",
    "data_dir_candidates = [cwd / \"data\", cwd.parent / \"data\"]  # supports both project root and notebook/ as CWD\n",
    "data_dir = next((p for p in data_dir_candidates if p.exists()), data_dir_candidates[0])\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "expected_csv_name = \"Retail_supply_chain - Retails Order Full Dataset.csv\"\n",
    "csv_path = data_dir / expected_csv_name\n",
    "\n",
    "if csv_path.exists():\n",
    "    print(f\"OK: CSV found -> {csv_path}\")\n",
    "else:\n",
    "    # Fallback: try to find a similar CSV recursively under the chosen data_dir\n",
    "    candidates = list(data_dir.rglob(\"Retail_supply_chain*Full*Dataset*.csv\"))\n",
    "    if candidates:\n",
    "        csv_path = candidates[0]\n",
    "        print(f\"Notice: expected file not found, using -> {csv_path}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(\n",
    "            f\"CSV not found. Expected at: {csv_path}\\n\"\n",
    "            f\"Place the file in the 'data/' folder at project root.\"\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "227d6a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: DB created -> c:\\Users\\pc\\Desktop\\PROJECTS\\Supply_chain_analysis\\data\\Retail_supply_chain.db  | Exists: True\n"
     ]
    }
   ],
   "source": [
    "# Create an empty SQLite database file under a relative data folder (./data or ../data).\n",
    "\n",
    "cwd = Path.cwd()\n",
    "data_dir_candidates = [cwd / \"data\", cwd.parent / \"data\"]\n",
    "data_dir = next((p for p in data_dir_candidates if p.exists()), data_dir_candidates[0])\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "db_path = data_dir / \"Retail_supply_chain.db\"\n",
    "conn = sqlite3.connect(db_path.as_posix())\n",
    "conn.close()\n",
    "\n",
    "print(f\"OK: DB created -> {db_path}  | Exists: {db_path.exists()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42e6e0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: loaded 9994 rows into stg_orders\n"
     ]
    }
   ],
   "source": [
    "# Helpers\n",
    "def to_iso_date(s: str):\n",
    "    if s is None:\n",
    "        return None\n",
    "    s = str(s).strip()\n",
    "    if not s:\n",
    "        return None\n",
    "    for fmt in (\"%Y-%m-%d\", \"%d/%m/%Y\", \"%m/%d/%Y\", \"%d-%m-%Y\", \"%m-%d-%Y\"):\n",
    "        try:\n",
    "            return datetime.datetime.strptime(s, fmt).date().isoformat()\n",
    "        except Exception:\n",
    "            continue\n",
    "    return s  # keep as-is if already ISO or unparseable but non-empty\n",
    "\n",
    "def parse_float(s):\n",
    "    if s is None:\n",
    "        return None\n",
    "    s = str(s).strip()\n",
    "    if not s:\n",
    "        return None\n",
    "    # Remove currency/percent and spaces (incl. non-breaking)\n",
    "    for ch in [\"â‚¬\", \"%\", \"\\u00A0\", \" \"]:\n",
    "        s = s.replace(ch, \"\")\n",
    "    # Normalize thousands/decimal separators\n",
    "    if \",\" in s and \".\" in s:\n",
    "        # Assume '.' as thousands and ',' as decimal (e.g., 1.234,56)\n",
    "        s = s.replace(\".\", \"\").replace(\",\", \".\")\n",
    "    elif \",\" in s:\n",
    "        # Assume ',' is decimal (e.g., 261,96)\n",
    "        s = s.replace(\",\", \".\")\n",
    "    try:\n",
    "        return float(s)\n",
    "    except Exception:\n",
    "        return None  # fallback: treat as missing\n",
    "\n",
    "def parse_int(s):\n",
    "    # Parse integers reliably even if given like \"1.000\" or \"1,000\"\n",
    "    f = parse_float(s)\n",
    "    if f is None:\n",
    "        return None\n",
    "    try:\n",
    "        return int(round(f))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# Paths (relative-safe: supports running from project root or ./notebook)\n",
    "cwd = Path.cwd()\n",
    "data_dir_candidates = [cwd / \"data\", cwd.parent / \"data\"]\n",
    "data_dir = next((p for p in data_dir_candidates if p.exists()), data_dir_candidates[0])\n",
    "db_path = data_dir / \"Retail_supply_chain.db\"\n",
    "expected_csv_name = \"Retail_supply_chain - Retails Order Full Dataset.csv\"\n",
    "csv_path = data_dir / expected_csv_name\n",
    "if not csv_path.exists():\n",
    "    candidates = list(data_dir.rglob(\"Retail_supply_chain*Full*Dataset*.csv\"))\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(f\"CSV not found at {csv_path}; place the file in the 'data/' folder.\")\n",
    "    csv_path = candidates[0]\n",
    "\n",
    "# Schema\n",
    "schema_sql = \"\"\"\n",
    "DROP TABLE IF EXISTS stg_orders;\n",
    "CREATE TABLE stg_orders (\n",
    "    row_id               INTEGER,\n",
    "    order_id             TEXT,\n",
    "    order_date           TEXT,   -- ISO 8601 YYYY-MM-DD\n",
    "    ship_date            TEXT,   -- ISO 8601 YYYY-MM-DD\n",
    "    ship_mode            TEXT,\n",
    "    customer_id          TEXT,\n",
    "    customer_name        TEXT,\n",
    "    segment              TEXT,\n",
    "    country              TEXT,\n",
    "    city                 TEXT,\n",
    "    state                TEXT,\n",
    "    postal_code          INTEGER,\n",
    "    region               TEXT,\n",
    "    retail_sales_people  TEXT,\n",
    "    product_id           TEXT,\n",
    "    category             TEXT,\n",
    "    sub_category         TEXT,\n",
    "    product_name         TEXT,\n",
    "    returned             TEXT,\n",
    "    sales                REAL,\n",
    "    quantity             INTEGER,\n",
    "    discount             REAL,\n",
    "    profit               REAL\n",
    ");\n",
    "CREATE INDEX IF NOT EXISTS idx_stg_orders_order_date ON stg_orders(order_date);\n",
    "CREATE INDEX IF NOT EXISTS idx_stg_orders_state ON stg_orders(state);\n",
    "CREATE INDEX IF NOT EXISTS idx_stg_orders_region ON stg_orders(region);\n",
    "CREATE INDEX IF NOT EXISTS idx_stg_orders_category ON stg_orders(category, sub_category);\n",
    "\"\"\"\n",
    "\n",
    "# Load\n",
    "conn = sqlite3.connect(db_path.as_posix())\n",
    "cur = conn.cursor()\n",
    "cur.executescript(schema_sql)\n",
    "conn.commit()\n",
    "\n",
    "with open(csv_path, \"r\", encoding=\"utf-8-sig\", newline=\"\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    rows = []\n",
    "    for r in reader:\n",
    "        rows.append((\n",
    "            parse_int(r.get(\"Row ID\")),\n",
    "            (r.get(\"Order ID\") or \"\").strip() or None,\n",
    "            to_iso_date(r.get(\"Order Date\")),\n",
    "            to_iso_date(r.get(\"Ship Date\")),\n",
    "            (r.get(\"Ship Mode\") or \"\").strip() or None,\n",
    "            (r.get(\"Customer ID\") or \"\").strip() or None,\n",
    "            (r.get(\"Customer Name\") or \"\").strip() or None,\n",
    "            (r.get(\"Segment\") or \"\").strip() or None,\n",
    "            (r.get(\"Country\") or \"\").strip() or None,\n",
    "            (r.get(\"City\") or \"\").strip() or None,\n",
    "            (r.get(\"State\") or \"\").strip() or None,\n",
    "            parse_int(r.get(\"Postal Code\")),\n",
    "            (r.get(\"Region\") or \"\").strip() or None,\n",
    "            (r.get(\"Retail Sales People\") or \"\").strip() or None,\n",
    "            (r.get(\"Product ID\") or \"\").strip() or None,\n",
    "            (r.get(\"Category\") or \"\").strip() or None,\n",
    "            (r.get(\"Sub-Category\") or \"\").strip() or None,\n",
    "            (r.get(\"Product Name\") or \"\").strip() or None,\n",
    "            (r.get(\"Returned\") or \"\").strip() or None,\n",
    "            parse_float(r.get(\"Sales\")),\n",
    "            parse_int(r.get(\"Quantity\")),\n",
    "            parse_float(r.get(\"Discount\")),\n",
    "            parse_float(r.get(\"Profit\"))\n",
    "        ))\n",
    "\n",
    "insert_sql = \"\"\"\n",
    "INSERT INTO stg_orders (\n",
    "    row_id, order_id, order_date, ship_date, ship_mode, customer_id, customer_name,\n",
    "    segment, country, city, state, postal_code, region, retail_sales_people,\n",
    "    product_id, category, sub_category, product_name, returned, sales, quantity, discount, profit\n",
    ") VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "\"\"\"\n",
    "cur.executemany(insert_sql, rows)\n",
    "conn.commit()\n",
    "\n",
    "total_rows = cur.execute(\"SELECT COUNT(*) FROM stg_orders;\").fetchone()[0]\n",
    "print(f\"OK: loaded {total_rows} rows into stg_orders\")\n",
    "\n",
    "conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f56aafba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: cleaning executed -> table 'Rsc_cleaned' created/refreshed.\n",
      "Counts (stg_raw, stg_dedup, rsc_cleaned): (9994, 9994, 9994)\n",
      "Row ID uniqueness (total, distinct): (9994, 9994)\n",
      "Returned distribution: [('NO', 9194), ('YES', 800)]\n",
      "Numeric sanity (bad_discount, bad_qty): (0, 0)\n",
      "Order date range (min, max): ('2014-01-02', '2017-12-30')\n"
     ]
    }
   ],
   "source": [
    "# Phase 2: build Rsc_cleaned from stg_orders (no new files; aligns with your last setup)\n",
    "\n",
    "# Resolve DB path (supports running from project root or ./notebook)\n",
    "cwd = Path.cwd()\n",
    "data_dir_candidates = [cwd / \"data\", cwd.parent / \"data\"]\n",
    "data_dir = next((p for p in data_dir_candidates if p.exists()), data_dir_candidates[0])\n",
    "db_path = data_dir / \"Retail_supply_chain.db\"\n",
    "\n",
    "# Cleaning / standardization SQL\n",
    "cleaning_sql = \"\"\"\n",
    "-- 1) Deduplicate on row_id (keep most recent by order_date; fallback by rowid)\n",
    "DROP TABLE IF EXISTS stg_orders_dedup;\n",
    "CREATE TABLE stg_orders_dedup AS\n",
    "WITH ranked AS (\n",
    "  SELECT\n",
    "    s.*,\n",
    "    ROW_NUMBER() OVER (\n",
    "      PARTITION BY s.row_id\n",
    "      ORDER BY s.order_date DESC, s.rowid ASC\n",
    "    ) AS rn\n",
    "  FROM stg_orders s\n",
    ")\n",
    "SELECT\n",
    "  row_id, order_id, order_date, ship_date, ship_mode, customer_id, customer_name,\n",
    "  segment, country, city, state, postal_code, region, retail_sales_people,\n",
    "  product_id, category, sub_category, product_name, returned, sales, quantity, discount, profit\n",
    "FROM ranked\n",
    "WHERE rn = 1;\n",
    "\n",
    "CREATE INDEX IF NOT EXISTS idx_dedup_order_date ON stg_orders_dedup(order_date);\n",
    "CREATE INDEX IF NOT EXISTS idx_dedup_region_state ON stg_orders_dedup(region, state);\n",
    "\n",
    "-- 2) Normalization view (text trimming, casing, returned standardization, numeric sanitization)\n",
    "DROP VIEW IF EXISTS clean_orders;\n",
    "CREATE VIEW clean_orders AS\n",
    "WITH base AS (\n",
    "  SELECT\n",
    "    CAST(row_id AS INTEGER)                  AS row_id,\n",
    "    TRIM(order_id)                           AS order_id,\n",
    "    TRIM(order_date)                         AS order_date,   -- ISO TEXT yyyy-mm-dd\n",
    "    TRIM(ship_date)                          AS ship_date,    -- ISO TEXT yyyy-mm-dd\n",
    "    TRIM(ship_mode)                          AS ship_mode,\n",
    "    TRIM(customer_id)                        AS customer_id,\n",
    "    TRIM(segment)                            AS segment,\n",
    "    UPPER(TRIM(country))                     AS country,\n",
    "    TRIM(city)                               AS city,\n",
    "    TRIM(state)                              AS state,\n",
    "    CAST(postal_code AS INTEGER)             AS postal_code,\n",
    "    UPPER(TRIM(region))                      AS region,\n",
    "    TRIM(product_id)                         AS product_id,\n",
    "    UPPER(TRIM(category))                    AS category,\n",
    "    UPPER(TRIM(sub_category))                AS sub_category,\n",
    "    TRIM(product_name)                       AS product_name,\n",
    "    CASE\n",
    "      WHEN returned IS NULL OR TRIM(returned) = '' THEN 'NO'\n",
    "      WHEN UPPER(TRIM(returned)) IN ('Y','YES','TRUE','T','1','RETURNED') THEN 'YES'\n",
    "      WHEN UPPER(TRIM(returned)) IN ('N','NO','FALSE','F','0','NOT RETURNED','NONE','NOT') THEN 'NO'\n",
    "      ELSE UPPER(TRIM(returned))\n",
    "    END                                      AS returned,\n",
    "    CAST(sales    AS REAL)                   AS sales,\n",
    "    CASE WHEN CAST(quantity AS REAL) < 0 THEN 0 ELSE CAST(quantity AS INTEGER) END AS quantity,\n",
    "    CASE\n",
    "      WHEN discount IS NULL THEN NULL\n",
    "      WHEN discount > 1.0 AND discount <= 100.0 THEN ROUND(discount/100.0, 4)\n",
    "      WHEN discount < 0.0 THEN 0.0\n",
    "      ELSE CAST(discount AS REAL)\n",
    "    END                                      AS discount,\n",
    "    CAST(profit   AS REAL)                   AS profit\n",
    "  FROM stg_orders_dedup\n",
    ")\n",
    "SELECT\n",
    "  row_id, order_id, order_date, ship_date, ship_mode, customer_id, segment, country,\n",
    "  city, state, postal_code, region, product_id, category, sub_category, product_name,\n",
    "  returned, sales, quantity, discount, profit\n",
    "FROM base;\n",
    "\n",
    "-- 3) Materialize for BI consumption as Rsc_cleaned (PII excluded)\n",
    "DROP TABLE IF EXISTS Rsc_cleaned;\n",
    "CREATE TABLE Rsc_cleaned AS\n",
    "SELECT * FROM clean_orders;\n",
    "\n",
    "-- 4) Indexes on Rsc_cleaned\n",
    "CREATE UNIQUE INDEX IF NOT EXISTS ux_rsc_row_id ON Rsc_cleaned(row_id);\n",
    "CREATE INDEX IF NOT EXISTS idx_rsc_order_date ON Rsc_cleaned(order_date);\n",
    "CREATE INDEX IF NOT EXISTS idx_rsc_region_state ON Rsc_cleaned(region, state);\n",
    "CREATE INDEX IF NOT EXISTS idx_rsc_category_sub ON Rsc_cleaned(category, sub_category);\n",
    "\"\"\"\n",
    "\n",
    "# Execute cleaning\n",
    "with sqlite3.connect(db_path.as_posix()) as conn:\n",
    "    conn.executescript(cleaning_sql)\n",
    "print(\"OK: cleaning executed -> table 'Rsc_cleaned' created/refreshed.\")\n",
    "\n",
    "# QA checks (concise)\n",
    "with sqlite3.connect(db_path.as_posix()) as conn:\n",
    "    cur = conn.cursor()\n",
    "    counts = cur.execute(\"\"\"\n",
    "        SELECT\n",
    "          (SELECT COUNT(*) FROM stg_orders),\n",
    "          (SELECT COUNT(*) FROM stg_orders_dedup),\n",
    "          (SELECT COUNT(*) FROM Rsc_cleaned)\n",
    "    \"\"\").fetchone()\n",
    "    uniq = cur.execute(\"\"\"\n",
    "        SELECT COUNT(*) AS total, COUNT(DISTINCT row_id) AS distinct_row_id\n",
    "        FROM Rsc_cleaned\n",
    "    \"\"\").fetchone()\n",
    "    returned = cur.execute(\"\"\"\n",
    "        SELECT returned, COUNT(*) FROM Rsc_cleaned\n",
    "        GROUP BY returned ORDER BY 2 DESC\n",
    "    \"\"\").fetchall()\n",
    "    num_sanity = cur.execute(\"\"\"\n",
    "        SELECT\n",
    "          SUM(CASE WHEN discount < 0 OR discount > 1 THEN 1 ELSE 0 END),\n",
    "          SUM(CASE WHEN quantity < 0 THEN 1 ELSE 0 END)\n",
    "        FROM Rsc_cleaned\n",
    "    \"\"\").fetchone()\n",
    "    date_range = cur.execute(\"\"\"\n",
    "        SELECT MIN(order_date), MAX(order_date) FROM Rsc_cleaned\n",
    "    \"\"\").fetchone()\n",
    "\n",
    "print(\"Counts (stg_raw, stg_dedup, rsc_cleaned):\", counts)\n",
    "print(\"Row ID uniqueness (total, distinct):\", uniq)\n",
    "print(\"Returned distribution:\", returned)\n",
    "print(\"Numeric sanity (bad_discount, bad_qty):\", num_sanity)\n",
    "print(\"Order date range (min, max):\", date_range)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7be7aa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: modeling created (dim_date, dim_geo, dim_product, fct_sales).\n",
      "Counts (Rsc_cleaned, fct_sales): (9994, 9994)\n",
      "dim_geo distinct (region, state, city): (4, 49, 531)\n",
      "dim_product distinct (product_id, category, subcat): (1862, 3, 17)\n",
      "dim_date range (min, max): ('2014-01-02', '2017-12-30')\n",
      "fct_sales NULLs (date_key, region, state, product_id): (0, 0, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "# Build dimensional views/tables from Rsc_cleaned for downstream KPI queries (SQLite)\n",
    "\n",
    "# Resolve DB path (supports running from project root or ./notebook)\n",
    "cwd = Path.cwd()\n",
    "data_dir_candidates = [cwd / \"data\", cwd.parent / \"data\"]\n",
    "data_dir = next((p for p in data_dir_candidates if p.exists()), data_dir_candidates[0])\n",
    "db_path = data_dir / \"Retail_supply_chain.db\"\n",
    "\n",
    "model_sql = \"\"\"\n",
    "-- =========================\n",
    "-- Star-lite modeling (SQLite)\n",
    "-- Source: Rsc_cleaned\n",
    "-- Creates: dim_date, dim_geo, dim_product (VIEWs) and fct_sales (TABLE)\n",
    "-- =========================\n",
    "\n",
    "-- 0) Safety drops\n",
    "DROP VIEW IF EXISTS dim_date;\n",
    "DROP VIEW IF EXISTS dim_geo;\n",
    "DROP VIEW IF EXISTS dim_product;\n",
    "DROP TABLE IF EXISTS fct_sales;\n",
    "\n",
    "-- 1) Date dimension (derived from order_date)\n",
    "CREATE VIEW dim_date AS\n",
    "WITH base AS (\n",
    "  SELECT DISTINCT order_date\n",
    "  FROM Rsc_cleaned\n",
    "  WHERE order_date IS NOT NULL\n",
    ")\n",
    "SELECT\n",
    "  order_date                                  AS date_key,             -- TEXT YYYY-MM-DD\n",
    "  SUBSTR(order_date, 1, 4)                    AS year,\n",
    "  SUBSTR(order_date, 6, 2)                    AS month,\n",
    "  SUBSTR(order_date, 9, 2)                    AS day,\n",
    "  (SUBSTR(order_date, 1, 4) || '-' || SUBSTR(order_date, 6, 2)) AS year_month,\n",
    "  CASE SUBSTR(order_date, 6, 2)\n",
    "    WHEN '01' THEN 'Q1' WHEN '02' THEN 'Q1' WHEN '03' THEN 'Q1'\n",
    "    WHEN '04' THEN 'Q2' WHEN '05' THEN 'Q2' WHEN '06' THEN 'Q2'\n",
    "    WHEN '07' THEN 'Q3' WHEN '08' THEN 'Q3' WHEN '09' THEN 'Q3'\n",
    "    ELSE 'Q4'\n",
    "  END AS quarter\n",
    "FROM base;\n",
    "\n",
    "-- 2) Geography dimension (Region/State/City)\n",
    "CREATE VIEW dim_geo AS\n",
    "SELECT DISTINCT\n",
    "  UPPER(TRIM(region)) AS region,\n",
    "  TRIM(state)         AS state,\n",
    "  TRIM(city)          AS city\n",
    "FROM Rsc_cleaned\n",
    "WHERE region IS NOT NULL\n",
    "  AND state  IS NOT NULL;\n",
    "\n",
    "-- 3) Product dimension (Category/Sub-Category/Product)\n",
    "CREATE VIEW dim_product AS\n",
    "SELECT DISTINCT\n",
    "  TRIM(product_id)      AS product_id,\n",
    "  UPPER(TRIM(category)) AS category,\n",
    "  UPPER(TRIM(sub_category)) AS sub_category,\n",
    "  TRIM(product_name)    AS product_name\n",
    "FROM Rsc_cleaned\n",
    "WHERE product_id IS NOT NULL;\n",
    "\n",
    "-- 4) Fact table (one row per order-product)\n",
    "CREATE TABLE fct_sales AS\n",
    "SELECT\n",
    "  r.row_id                       AS row_id,         -- surrogate PK (unique)\n",
    "  r.order_id                     AS order_id,\n",
    "  r.order_date                   AS date_key,       -- join to dim_date.date_key\n",
    "  r.region                       AS region,         -- join to dim_geo.region\n",
    "  r.state                        AS state,          -- join to dim_geo.state\n",
    "  r.city                         AS city,           -- optional join on city\n",
    "  r.product_id                   AS product_id,     -- join to dim_product.product_id\n",
    "  r.category                     AS category,       -- redundant for ease in BI\n",
    "  r.sub_category                 AS sub_category,   -- redundant for ease in BI\n",
    "  r.ship_mode                    AS ship_mode,\n",
    "  r.returned                     AS returned,       -- 'YES'/'NO'\n",
    "  r.sales                        AS sales,\n",
    "  r.quantity                     AS quantity,\n",
    "  r.discount                     AS discount,       -- 0..1\n",
    "  r.profit                       AS profit\n",
    "FROM Rsc_cleaned r;\n",
    "\n",
    "-- 5) Indexes for BI performance\n",
    "CREATE UNIQUE INDEX IF NOT EXISTS ux_fct_row_id ON fct_sales(row_id);\n",
    "CREATE INDEX IF NOT EXISTS idx_fct_date ON fct_sales(date_key);\n",
    "CREATE INDEX IF NOT EXISTS idx_fct_region_state ON fct_sales(region, state);\n",
    "CREATE INDEX IF NOT EXISTS idx_fct_product ON fct_sales(product_id);\n",
    "CREATE INDEX IF NOT EXISTS idx_fct_category_sub ON fct_sales(category, sub_category);\n",
    "\n",
    "-- 6) Lightweight integrity checks (counts should match)\n",
    "\"\"\"\n",
    "\n",
    "# Execute modeling\n",
    "with sqlite3.connect(db_path.as_posix()) as conn:\n",
    "    conn.executescript(model_sql)\n",
    "print(\"OK: modeling created (dim_date, dim_geo, dim_product, fct_sales).\")\n",
    "\n",
    "# Quick QA\n",
    "with sqlite3.connect(db_path.as_posix()) as conn:\n",
    "    cur = conn.cursor()\n",
    "    cnts = cur.execute(\"\"\"\n",
    "        SELECT\n",
    "          (SELECT COUNT(*) FROM Rsc_cleaned),\n",
    "          (SELECT COUNT(*) FROM fct_sales)\n",
    "    \"\"\").fetchone()\n",
    "    geo_keys = cur.execute(\"\"\"\n",
    "        SELECT\n",
    "          (SELECT COUNT(DISTINCT region) FROM dim_geo),\n",
    "          (SELECT COUNT(DISTINCT state)  FROM dim_geo),\n",
    "          (SELECT COUNT(DISTINCT city)   FROM dim_geo)\n",
    "    \"\"\").fetchone()\n",
    "    prod_keys = cur.execute(\"\"\"\n",
    "        SELECT\n",
    "          (SELECT COUNT(DISTINCT product_id)  FROM dim_product),\n",
    "          (SELECT COUNT(DISTINCT category)    FROM dim_product),\n",
    "          (SELECT COUNT(DISTINCT sub_category) FROM dim_product)\n",
    "    \"\"\").fetchone()\n",
    "    date_minmax = cur.execute(\"\"\"\n",
    "        SELECT MIN(date_key), MAX(date_key) FROM dim_date\n",
    "    \"\"\").fetchone()\n",
    "    null_checks = cur.execute(\"\"\"\n",
    "        SELECT\n",
    "          SUM(CASE WHEN date_key IS NULL THEN 1 ELSE 0 END),\n",
    "          SUM(CASE WHEN region   IS NULL THEN 1 ELSE 0 END),\n",
    "          SUM(CASE WHEN state    IS NULL THEN 1 ELSE 0 END),\n",
    "          SUM(CASE WHEN product_id IS NULL THEN 1 ELSE 0 END)\n",
    "        FROM fct_sales\n",
    "    \"\"\").fetchone()\n",
    "\n",
    "print(\"Counts (Rsc_cleaned, fct_sales):\", cnts)               # expect equal (row-per-row)\n",
    "print(\"dim_geo distinct (region, state, city):\", geo_keys)    # sanity for mapping\n",
    "print(\"dim_product distinct (product_id, category, subcat):\", prod_keys)\n",
    "print(\"dim_date range (min, max):\", date_minmax)\n",
    "print(\"fct_sales NULLs (date_key, region, state, product_id):\", null_checks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8301425c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (supply_chain_venv)",
   "language": "python",
   "name": "supply_chain_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
